{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b64f06-d49a-4760-ada8-f4fabfc0b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "330fe83e-9ea5-4bbc-83c8-f8cd239f5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter, CharacterTextSplitter \n",
    "\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019ae2c6-144e-4303-a6c5-cd8b618df658",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Check if variables are correctly loaded from .env\n",
    "AZURE_OPENAI_API_KEY_2 = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "if not AZURE_OPENAI_API_KEY_2:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "DEPLOYMENT_NAME_LLM = os.getenv('DEPLOYMENT_NAME_LLM')\n",
    "if not DEPLOYMENT_NAME_LLM:\n",
    "    raise ValueError(\"DEPLOYMENT_NAME_LLM not found in environment variables\")\n",
    "\n",
    "API_VERSION = os.getenv('API_VERSION')\n",
    "if not API_VERSION:\n",
    "    raise ValueError(\"API_VERSION not found in environment variables\")\n",
    "    \n",
    "AZURE_ENDPOINT_LLM = os.getenv('AZURE_ENDPOINT_LLM')\n",
    "if not AZURE_ENDPOINT_LLM:\n",
    "    raise ValueError(\"AZURE_ENDPOINT_LLM not found in environment variables\")\n",
    "\n",
    "EMBEDDING_KEY = os.getenv('EMBEDDING_KEY')\n",
    "if not EMBEDDING_KEY:\n",
    "    raise ValueError(\"EMBEDDING_KEY not found in environment variables\")\n",
    "\n",
    "DEPLOYMENT_NAME_EMBEDDING = os.getenv('DEPLOYMENT_NAME_EMBEDDING')\n",
    "if not DEPLOYMENT_NAME_EMBEDDING:\n",
    "    raise ValueError(\"DEPLOYMENT_NAME_EMBEDDING not found in environment variables\")\n",
    "    \n",
    "AZURE_ENDPOINT_EMBEDDING = os.getenv('AZURE_ENDPOINT_EMBEDDING')\n",
    "if not AZURE_ENDPOINT_EMBEDDING:\n",
    "    raise ValueError(\"AZURE_ENDPOINT_EMBEDDING not found in environment variables\")\n",
    "\n",
    "API_BASE_EMBEDDING = os.getenv('API_BASE_EMBEDDING')\n",
    "if not API_BASE_EMBEDDING:\n",
    "    raise ValueError(\"API_BASE_EMBEDDING not found in environment variables\")\n",
    "\n",
    "ELASTICSEARCH_USER = os.getenv('ELASTICSEARCH_USER')\n",
    "if not API_BASE_EMBEDDING:\n",
    "    raise ValueError(\"ELASTICSEARCH_USER not found in environment variables\")\n",
    "\n",
    "ELASTICSEARCH_PASSWORD = os.getenv('ELASTICSEARCH_PASSWORD')\n",
    "if not API_BASE_EMBEDDING:\n",
    "    raise ValueError(\"ELASTICSEARCH_PASSWORD not found in environment variables\")\n",
    "\n",
    "ELASTICSEARCH_API_KEY = os.getenv('ELASTICSEARCH_API_KEY')\n",
    "if not API_BASE_EMBEDDING:\n",
    "    raise ValueError(\"ELASTICSEARCH_API_KEY not found in environment variables\")\n",
    "\n",
    "ELASTICSEARCH_ENDPOINT = os.getenv('ELASTICSEARCH_ENDPOINT')\n",
    "if not API_BASE_EMBEDDING:\n",
    "    raise ValueError(\"ELASTICSEARCH_ENDPOINT not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9924c3-fd3e-4a49-a05b-827d6edba6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/A Survey of Time Series Foundation Models Generalizing Time Series.pdf\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 2000\n",
    "chunk_overlap = 400\n",
    "\n",
    "# Documentos\n",
    "dict_documents = {}\n",
    "dict_documents[1] = 'A Survey of Time Series Foundation Models Generalizing Time Series.pdf'\n",
    "# dict_documents[2] = 'DeepSeek-R1 Incentivizing Reasoning Capability in LLMs via.pdf'\n",
    "\n",
    "# Seleciona arquivos\n",
    "pdf_path = {}\n",
    "pdf_path[1] = \"data/\" + dict_documents[1]\n",
    "# pdf_path[2] = \"data/\" + dict_documents[2]\n",
    "\n",
    "print(pdf_path[1])\n",
    "# print(pdf_path[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51813e8a-7629-4404-9588-6c492fa3952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_page_markers(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PdfReader(file)\n",
    "        text_with_page_markers = []\n",
    "        for i in range(len(reader.pages)):\n",
    "            page = reader.pages[i].extract_text()\n",
    "            # Add page marker\n",
    "            text_with_page_markers.append(f\"[[PAGE {i + 1}]]\\n{page}\")\n",
    "    return '\\n'.join(text_with_page_markers)\n",
    "\n",
    "# Assuming text_with_page_markers is obtained from the previous step\n",
    "def chunk_text_with_page_tracking(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    chunk_page_mapping = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Find the pages in the chunk by looking for the page markers\n",
    "        start_page = None\n",
    "        end_page = None\n",
    "\n",
    "        flag_first_line = 1\n",
    "        for line in chunk.splitlines():\n",
    "            if \"[[PAGE\" in line:   # The notation '[[PAGE' originates from the splitting function, not from the document.\n",
    "                page_num = int(line.split(\"[[PAGE \")[1].split(\"]]\")[0])\n",
    "                if start_page is None:\n",
    "                    if flag_first_line == 1:\n",
    "                        start_page = page_num\n",
    "                    else:\n",
    "                        # If it starts in the middle of the page, select start_page as the previous page.\n",
    "                        start_page = page_num - 1\n",
    "                end_page = page_num\n",
    "            flag_first_line = 0\n",
    "\n",
    "        # If the string \"[[PAGE \" is not found, it means there was no page change.\n",
    "        if start_page is None:\n",
    "            start_page = end_page_aux\n",
    "            end_page = end_page_aux\n",
    "        end_page_aux = end_page\n",
    "        \n",
    "        chunk_page_mapping.append({\n",
    "            \"chunk\": chunk,\n",
    "            \"start_page\": start_page,\n",
    "            \"end_page\": end_page\n",
    "        })\n",
    "        \n",
    "    return chunk_page_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21672d34-f1ad-4bbb-a645-220f719ce0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "pdf_chunked_data = {}\n",
    "for key in tqdm(pdf_path):\n",
    "    text_with_pages = extract_text_with_page_markers(pdf_path[key])\n",
    "    pdf_chunked_data[key] = chunk_text_with_page_tracking(text_with_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "203df37c-03cd-4f65-af83-2a00bb9a7ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line, we discuss effectiveness through two key phases: data collection and alignment, architectural design. Regarding the\n",
      "second line, we identify two adaption paradigms, i.e. embedding visible LLM adaption and textual visible LLM adaption.\n",
      "Under each adaption paradigm, we discuss the LLM utilization, time series extraction and multi-modal data fusion. The\n",
      "time series extraction includes challenges like obtaining appropriate time series representation, aligning temporal space\n",
      "and LLM space, identifying time series properties and patterns. Additionally, we examine diverse roles of LLMs that\n",
      "[[PAGE 5]]\n",
      "A Survey of Time Series Foundation Models 5\n",
      "SurveyEffectiveness Efficiency Explainability Domain\n",
      "Foundation Model Pre-trained from Scratch\n",
      "for Time SeriesLLM Adaption for Time Series\n",
      "Efficient\n",
      "TuningLocal\n",
      "ExplanationGlobal\n",
      "ExplanationSpecific or\n",
      "GeneralAdaption to\n",
      "Time SeriesAlignmentTime Series\n",
      "CharacteristicsMultimodal\n",
      "[84] ✗ ✓ ✓ ✗ ✓ ✗ ✗ ✗ Specific\n",
      "[83] ✓ ✓ ✓ ✗ ✓ ✗ ✗ ✗ Both\n",
      "[154] ✗ ✓ ✓ ✓ ✗ ✗ ✗ ✗ General\n",
      "[81] ✗ ✓ ✓ ✓ ✓ ✓ ✗ ✗ Both\n",
      "[205] ✓ ✓ ✓ ✗ ✓ ✗ ✗ ✗ Both\n",
      "Ours ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Both\n",
      "Table 1. Comparative overview of related surveys, spanning four aspects: Effectiveness, Efficiency, Explainability, and\n",
      "Domain.\n",
      "further increase the effectiveness of LLM adaption. (2) How to pre-train or fine-tune foundation models efficiently for\n",
      "time series tasks? Given that this area is emerging, current efficient techniques are adapted from NLP. Therefore, we\n",
      "first provide a brief overview of cutting-edge NLP efficient methods that are transferable to this context. We then discuss\n",
      "the efficiency under different tuning paradigms and summarize efficient methods already in use. (3) How to obtain\n",
      "explainability of foundation models’ behaviors or decisions in time series applications? The practical deployment of\n",
      "models necessitates explainability. We start by exploring the concept of explainability in AI, highlighting both global and\n"
     ]
    }
   ],
   "source": [
    "# Show chunk_page_mapping example. \n",
    "print(pdf_chunked_data[1][10]['chunk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128b3d2e-edd1-4c5b-af21-04322600777b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_chunked_data[1][10]['start_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f32a1b1-203e-4b40-98ee-3660af04229c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_chunked_data[1][10]['end_page']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7fdb00-e1d2-48ed-b06b-fcdf533becd3",
   "metadata": {},
   "source": [
    "## Create VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc7309d-9fa2-462a-b5d6-9604e2673662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_vectordb_full_text_and_questions():\n",
    "    '''\n",
    "    collection_full_text: Connection to the full-text index.\n",
    "    collection_questions_text: Connection to the question-based index.\n",
    "    es: Direct Elasticsearch client instance.\n",
    "    '''\n",
    "    from langchain_openai import AzureOpenAIEmbeddings\n",
    "    from langchain_elasticsearch import ElasticsearchStore\n",
    "    from elasticsearch import Elasticsearch\n",
    "\n",
    "    # Embedding for LangChain\n",
    "    embedding_function_to_langchain = AzureOpenAIEmbeddings(\n",
    "        model = 'text-embedding-3-small',\n",
    "        api_key = EMBEDDING_KEY,\n",
    "        deployment = DEPLOYMENT_NAME_EMBEDDING,\n",
    "        azure_endpoint = AZURE_ENDPOINT_EMBEDDING\n",
    "    ) \n",
    "\n",
    "    dict_return = {}\n",
    "    # Conect to elastic search\n",
    "    dict_return['collection_full_text'] = ElasticsearchStore(\n",
    "        es_url = ELASTICSEARCH_ENDPOINT,\n",
    "        index_name = \"collection_full_text\",\n",
    "        embedding = embedding_function_to_langchain,\n",
    "        es_user = ELASTICSEARCH_USER,\n",
    "        es_password = ELASTICSEARCH_PASSWORD,\n",
    "    )\n",
    "    \n",
    "    dict_return['collection_questions_text'] = ElasticsearchStore(\n",
    "        es_url = ELASTICSEARCH_ENDPOINT,\n",
    "        index_name = \"collection_questions_text\",\n",
    "        embedding = embedding_function_to_langchain,\n",
    "        es_user = ELASTICSEARCH_USER,\n",
    "        es_password = ELASTICSEARCH_PASSWORD,\n",
    "    )\n",
    "\n",
    "    dict_return['es'] = Elasticsearch(\n",
    "        ELASTICSEARCH_ENDPOINT,\n",
    "        basic_auth=(ELASTICSEARCH_USER, ELASTICSEARCH_PASSWORD)\n",
    "    )\n",
    "    \n",
    "    return dict_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418d91ca-c81a-4a05-ba08-7e145f0a72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary information about the collection in the vector db\n",
    "index_name_collection_full_text = 'collection_full_text'\n",
    "index_name_collection_questions_text = 'collection_questions_text'\n",
    "# Connect with elastic seach and langchain\n",
    "dict_vectordb = return_vectordb_full_text_and_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6dc1fdd-726a-48d9-823f-976b246a7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_highest_vectordb_id\n",
    "# Get the highest id in vector db so we can add new entries.\n",
    "def get_highest_vectordb_id(es_fc, index_name):\n",
    "    # Check if the index exists\n",
    "    if not es_fc.indices.exists(index=index_name):\n",
    "        print(f\"Index '{index_name}' does not exist.\")\n",
    "        return 0\n",
    "        \n",
    "    query = {\n",
    "        \"size\": 0,  # We don't need to return any actual documents, just the aggregation\n",
    "        \"aggs\": {\n",
    "            \"max_vector_db_id\": {\n",
    "                \"max\": {\n",
    "                    \"field\": \"metadata.vector_db_id\"    \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Perform the search with the aggregation\n",
    "    response = es_fc.search(index = index_name, body = query)\n",
    "    \n",
    "    # Extract the maximum value from the aggregation response\n",
    "    max_vector_db_id = response['aggregations']['max_vector_db_id']['value']\n",
    "    if max_vector_db_id == None:\n",
    "        return 0\n",
    "    return max_vector_db_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca24270f-33d0-466a-9312-5510f11c1459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'collection_full_text' does not exist.\n",
      "----------------------------------------------\n",
      "Index 'collection_questions_text' does not exist.\n",
      "Both collection should have the same max index.\n",
      "Largest index for collection full_text: 0\n",
      "Largest index for collection questions: 0\n"
     ]
    }
   ],
   "source": [
    "# Get last index to add documents\n",
    "# Retrieve documents with metadata, which may contain IDs\n",
    "highest_id_collection_full_text = get_highest_vectordb_id(\n",
    "    index_name = index_name_collection_full_text, \n",
    "    es_fc = dict_vectordb['es']\n",
    ")\n",
    "print('----------------------------------------------')\n",
    "highest_id_collection_questions_text = get_highest_vectordb_id(\n",
    "    index_name = index_name_collection_questions_text, \n",
    "    es_fc = dict_vectordb['es']\n",
    ")\n",
    "print('Both collection should have the same max index.')\n",
    "print(f\"Largest index for collection full_text: {highest_id_collection_full_text}\")\n",
    "print(f\"Largest index for collection questions: {highest_id_collection_questions_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91d809-19d8-464e-a2f4-d73a95715aff",
   "metadata": {},
   "source": [
    "## question-augmented vector retrieval (QAVR)\n",
    "\n",
    "A dual-vector storage approach for contextual augmentation.\n",
    "\n",
    "- Collection for Texts: Storing the original text chunks in one collection for direct semantic retrieval.\n",
    "- Collection for Hypothetical Questions: Creating another collection with hypothetical questions that each text chunk could answer. This enhances retrieval by matching user queries with questions semantically similar to their intent, rather than directly to the text.\n",
    "\n",
    "Related Concepts:\n",
    "- Augmented Retrieval: Augmenting the dataset with additional metadata, in this case, hypothetical questions.\n",
    "- Embedding-based Retrieval with Intent Mapping: Mapping potential user intents (questions) to the text that best answers them.\n",
    "- Query Expansion: While query expansion typically involves modifying the user's query, your approach effectively expands the dataset to cover a broader range of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd2c5ed5-555e-4ab0-a92e-b02c6008303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_hypothetical_questions\n",
    "def llm_hypothetical_questions():\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    from langchain_openai import AzureOpenAIEmbeddings\n",
    "    from langchain.prompts import PromptTemplate\n",
    "    # Model used\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name = DEPLOYMENT_NAME_LLM,\n",
    "        model_name = \"gpt-4o-mini\",\n",
    "        api_version = API_VERSION,\n",
    "        azure_endpoint = AZURE_ENDPOINT_LLM,\n",
    "        api_key = AZURE_OPENAI_API_KEY_2,\n",
    "    )\n",
    "    # Embedding for LangChain\n",
    "    # Embedding for LangChain\n",
    "    embedding_function_to_langchain = AzureOpenAIEmbeddings(\n",
    "        model = 'text-embedding-3-small',\n",
    "        api_key = EMBEDDING_KEY,\n",
    "        deployment = DEPLOYMENT_NAME_EMBEDDING,\n",
    "        azure_endpoint = AZURE_ENDPOINT_EMBEDDING\n",
    "    ) \n",
    "    # Define template for answers\n",
    "    # Build prompt\n",
    "    template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "    {context}\n",
    "    If you can't make a answer with context, just say that you don't know, don't try to make up an answer.\n",
    "    Do not hallucinate.\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    llm_chain = prompt | llm\n",
    "    \n",
    "    question = \"\"\"Make as many relevant specific and/or generic questions that the above text can answer.\n",
    "    If you can't make a question with context, just don't say anything, don't try to make up an questions just to fill the quota.\"\"\"\n",
    "\n",
    "    dict_return = {}\n",
    "    dict_return['llm_chain'] = llm_chain\n",
    "    dict_return['question'] = question \n",
    "\n",
    "    return dict_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c83847e4-33a1-49b1-a215-f14973d51c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothetical Questions\n",
    "dict_llm_hypothetical_questions = llm_hypothetical_questions()\n",
    "llm_chain = dict_llm_hypothetical_questions['llm_chain']\n",
    "question = dict_llm_hypothetical_questions['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e82bdd52-2a72-4a5c-87ec-d055d7f2ff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello.\n",
      "Who am I?\n",
      "I'm just a test to verify it this documment was correctly included in the vectorDB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New text\n",
    "# Agent's introdutory text\n",
    "text_who_am_I = \"\"\"\n",
    "Hello.\n",
    "Who am I?\n",
    "I'm just a test to verify it this documment was correctly included in the vectorDB.\n",
    "\"\"\"\n",
    "print(text_who_am_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6485197-0a3d-4ca4-8df3-b4cf923953e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding documents to Elasticsearch:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e32400da-9ced-440d-86ff-24d18a0d0e5f']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add documents in vector db\n",
    "vector_db_id = highest_id_collection_full_text + 1\n",
    "\n",
    "# Prepare bulk data\n",
    "bulk_full_text = []\n",
    "bulk_questions_text = []\n",
    "\n",
    "print('Adding documents to Elasticsearch:')\n",
    "\n",
    "# Add an introdutory text\n",
    "document_name = \"Agent_description\"\n",
    "# Add full text chunk\n",
    "bulk_full_text.append(Document\n",
    "    (\n",
    "        page_content = text_who_am_I,\n",
    "        metadata = {\n",
    "            \"document_name\": document_name,  \n",
    "            \"vector_db_id\": vector_db_id, \n",
    "            'first_page': -1, # This is a custom added text, so there isn't a first and last page.\n",
    "            'last_page': -1,\n",
    "            'added_by': 'default',\n",
    "        },\n",
    "    )\n",
    ")\n",
    "# Make questions\n",
    "context = text_who_am_I\n",
    "result = llm_chain.invoke({\"context\": context, \"question\": question})\n",
    "# Add questions in the collection\n",
    "bulk_questions_text.append(Document\n",
    "    (\n",
    "        page_content = result.content,\n",
    "        metadata = {\n",
    "            \"document_name\": document_name,\n",
    "            \"vector_db_id\": vector_db_id,\n",
    "            'first_page': -1,\n",
    "            'last_page': -1,\n",
    "            'added_by': 'default',\n",
    "        },\n",
    "    )\n",
    ")\n",
    "vector_db_id += 1\n",
    "# Bulk index the data into Elasticsearch\n",
    "uuids_bulk_full_text = [str(uuid4()) for _ in range(len(bulk_full_text))]\n",
    "dict_vectordb['collection_full_text'].add_documents(documents = bulk_full_text, \n",
    "                                                         ids = uuids_bulk_full_text)\n",
    "\n",
    "uuids_bulk_questions_text = [str(uuid4()) for _ in range(len(bulk_questions_text))]\n",
    "dict_vectordb['collection_questions_text'].add_documents(documents = bulk_questions_text, \n",
    "                                                              ids = uuids_bulk_questions_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11ec06df-921d-4065-a787-facbf678bb19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 110/110 [04:28<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added to Elasticsearch successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add papers\n",
    "for key in pdf_chunked_data:\n",
    "    document_name = dict_documents[key]\n",
    "    for e in tqdm(pdf_chunked_data[key]):\n",
    "        context = e['chunk']\n",
    "        \n",
    "        # Add full text chunk\n",
    "        bulk_full_text.append(Document\n",
    "            (\n",
    "                page_content = context,\n",
    "                metadata = {\n",
    "                    \"document_name\": document_name,\n",
    "                    \"vector_db_id\": vector_db_id,\n",
    "                    'first_page': e['start_page'],\n",
    "                    'last_page': e['end_page'],\n",
    "                    'added_by': 'default',\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Make question using LLM chain\n",
    "        result = llm_chain.invoke({\"context\": context, \"question\": question})\n",
    "        \n",
    "        # Add question response chunk\n",
    "        bulk_questions_text.append(Document\n",
    "            (\n",
    "                page_content = result.content,\n",
    "                metadata = {\n",
    "                    \"document_name\": document_name,\n",
    "                    \"vector_db_id\": vector_db_id,\n",
    "                    'first_page': e['start_page'],\n",
    "                    'last_page': e['end_page'],\n",
    "                    'added_by': 'default',\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        vector_db_id += 1\n",
    "\n",
    "# Bulk index the data into Elasticsearch\n",
    "uuids_bulk_full_text = [str(uuid4()) for _ in range(len(bulk_full_text))]\n",
    "dict_vectordb['collection_full_text'].add_documents(documents = bulk_full_text, \n",
    "                                                         ids = uuids_bulk_full_text)\n",
    "\n",
    "uuids_bulk_questions_text = [str(uuid4()) for _ in range(len(bulk_questions_text))]\n",
    "dict_vectordb['collection_questions_text'].add_documents(documents = bulk_questions_text, \n",
    "                                                              ids = uuids_bulk_questions_text)\n",
    "\n",
    "print(\"Documents added to Elasticsearch successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25dd9ca-3764-4463-9e44-b463346ee474",
   "metadata": {},
   "source": [
    "## Add customized document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e546fc1-ed3a-4269-8972-3b56087741e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "person_name = \"Max Wienandts\"\n",
    "document_name = \"Custon added\"\n",
    "first_page = -1\n",
    "last_page = -1\n",
    "\n",
    "text_to_add = \"\"\"\n",
    "This is a brand new text.\n",
    "The correct number to choose is 42.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "954e55f3-5abd-49c4-9c83-c19928d2fc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest index: 111.0\n"
     ]
    }
   ],
   "source": [
    "# Chunk new text\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap\n",
    "    )\n",
    "chunks = text_splitter.split_text(text_to_add)\n",
    "\n",
    "# Get last index\n",
    "highest_id_collection_full_text = get_highest_vectordb_id(\n",
    "    index_name = index_name_collection_full_text, \n",
    "    es_fc = dict_vectordb['es']\n",
    ")\n",
    "print(f'Largest index: {highest_id_collection_full_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a50c8b08-5a64-432e-a17c-0cb26f62e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents added to Elasticsearch successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add new text in the full text collection\n",
    "vector_db_id = highest_id_collection_full_text + 1 \n",
    "for e in tqdm(chunks):\n",
    "    context = e\n",
    "    # Add full text chunk\n",
    "    bulk_full_text.append(Document\n",
    "        (\n",
    "            page_content = context,\n",
    "            metadata = {\n",
    "                \"document_name\": document_name,\n",
    "                \"vector_db_id\": vector_db_id,\n",
    "                'first_page': first_page,\n",
    "                'last_page': last_page,\n",
    "                'added_by': person_name,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Make question using LLM chain\n",
    "    result = llm_chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    # Add question response chunk\n",
    "    bulk_questions_text.append(Document\n",
    "        (\n",
    "            page_content = result.content,\n",
    "            metadata = {\n",
    "                \"document_name\": document_name,\n",
    "                \"vector_db_id\": vector_db_id,\n",
    "                'first_page': first_page,\n",
    "                'last_page': last_page,\n",
    "                'added_by': person_name,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    vector_db_id += 1\n",
    "\n",
    "# Bulk index the data into Elasticsearch\n",
    "uuids_bulk_full_text = [str(uuid4()) for _ in range(len(bulk_full_text))]\n",
    "dict_vectordb['collection_full_text'].add_documents(documents = bulk_full_text, \n",
    "                                                         ids = uuids_bulk_full_text)\n",
    "\n",
    "uuids_bulk_questions_text = [str(uuid4()) for _ in range(len(bulk_questions_text))]\n",
    "dict_vectordb['collection_questions_text'].add_documents(documents = bulk_questions_text, \n",
    "                                                              ids = uuids_bulk_questions_text)\n",
    "\n",
    "print(\"Documents added to Elasticsearch successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657758d-6f57-4385-8687-3b4a4a0cbacb",
   "metadata": {},
   "source": [
    "## Verify if collections have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f143a9-6e8d-480f-b532-8f6d3a5374e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Both collection should have the same max index.\n",
      "Largest index for collection full_text: 112.0\n",
      "Largest index for collection questions: 112.0\n"
     ]
    }
   ],
   "source": [
    "# Get last index to add documents\n",
    "# Retrieve documents with metadata, which may contain IDs\n",
    "highest_id_collection_full_text = get_highest_vectordb_id(\n",
    "    index_name = index_name_collection_full_text, \n",
    "    es_fc = dict_vectordb['es']\n",
    ")\n",
    "print('----------------------------------------------')\n",
    "highest_id_collection_questions_text = get_highest_vectordb_id(\n",
    "    index_name = index_name_collection_questions_text, \n",
    "    es_fc = dict_vectordb['es']\n",
    ")\n",
    "print('Both collection should have the same max index.')\n",
    "print(f\"Largest index for collection full_text: {highest_id_collection_full_text}\")\n",
    "print(f\"Largest index for collection questions: {highest_id_collection_questions_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954616f-31bb-4285-9cce-5b968a0b579e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d918ac-7974-4753-b6fa-76c5b86b4f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0ee95-68b6-47f4-ae38-1f6bc635a224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ac4f4-377f-4b2f-a864-3071c58cb011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
