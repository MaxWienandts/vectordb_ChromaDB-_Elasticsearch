{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509f8c8b-84e2-4c44-8325-c183787e9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import chromadb\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter, CharacterTextSplitter \n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a143654-2061-4569-8f08-0c31e389db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Check if variables are correctly loaded from .env\n",
    "AZURE_OPENAI_API_KEY_2 = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "if not AZURE_OPENAI_API_KEY_2:\n",
    "    raise ValueError(\"AZURE_OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "DEPLOYMENT_NAME_LLM = os.getenv('DEPLOYMENT_NAME_LLM')\n",
    "if not DEPLOYMENT_NAME_LLM:\n",
    "    raise ValueError(\"DEPLOYMENT_NAME_LLM not found in environment variables\")\n",
    "\n",
    "API_VERSION = os.getenv('API_VERSION')\n",
    "if not API_VERSION:\n",
    "    raise ValueError(\"API_VERSION not found in environment variables\")\n",
    "    \n",
    "AZURE_ENDPOINT_LLM = os.getenv('AZURE_ENDPOINT_LLM')\n",
    "if not AZURE_ENDPOINT_LLM:\n",
    "    raise ValueError(\"AZURE_ENDPOINT_LLM not found in environment variables\")\n",
    "\n",
    "EMBEDDING_KEY = os.getenv('EMBEDDING_KEY')\n",
    "if not EMBEDDING_KEY:\n",
    "    raise ValueError(\"EMBEDDING_KEY not found in environment variables\")\n",
    "\n",
    "DEPLOYMENT_NAME_EMBEDDING = os.getenv('DEPLOYMENT_NAME_EMBEDDING')\n",
    "if not DEPLOYMENT_NAME_EMBEDDING:\n",
    "    raise ValueError(\"DEPLOYMENT_NAME_EMBEDDING not found in environment variables\")\n",
    "    \n",
    "AZURE_ENDPOINT_EMBEDDING = os.getenv('AZURE_ENDPOINT_EMBEDDING')\n",
    "if not AZURE_ENDPOINT_EMBEDDING:\n",
    "    raise ValueError(\"AZURE_ENDPOINT_EMBEDDING not found in environment variables\")\n",
    "\n",
    "API_BASE_EMBEDDING = os.getenv('API_BASE_EMBEDDING')\n",
    "if not API_BASE_EMBEDDING:\n",
    "    raise ValueError(\"API_BASE_EMBEDDING not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9c876c-44a5-40fe-bc96-b0bd21ffa599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados necessários para update\n",
    "added_by = \"Max Wienandts\"\n",
    "document_name = \"Custon added\"\n",
    "first_page = -1\n",
    "last_page = -1\n",
    "\n",
    "text_to_add = \"\"\"\n",
    "This is an example of how to add more information in your ChromaDb.\n",
    "To do so, just read this notebook.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f790b1-fb2f-4c44-8502-35d15ca610b7",
   "metadata": {},
   "source": [
    "## Chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237d8296-1da5-4f84-a0f2-4fd41ae5409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1500,\n",
    "        chunk_overlap = 400\n",
    "    )\n",
    "chunks = text_splitter.split_text(text_to_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96427118-4d22-4217-80d3-14c27a90ccda",
   "metadata": {},
   "source": [
    "## Hypothetical Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e0e889-2949-49b4-a3ee-f4ea8d78c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model used\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name = DEPLOYMENT_NAME_LLM,\n",
    "    model_name = \"gpt-4o-mini\",\n",
    "    api_version = API_VERSION,\n",
    "    azure_endpoint = AZURE_ENDPOINT_LLM,\n",
    "    api_key = AZURE_OPENAI_API_KEY_2,\n",
    ")\n",
    "# Embedding for LangChain\n",
    "embedding_function_to_langchain = AzureOpenAIEmbeddings(\n",
    "    model = 'text-embedding-3-small',\n",
    "    api_key=EMBEDDING_KEY,\n",
    "    deployment = DEPLOYMENT_NAME_EMBEDDING,\n",
    "    azure_endpoint = AZURE_ENDPOINT_EMBEDDING,\n",
    ") \n",
    "\n",
    "# Embedding for ChromaDB\n",
    "embedding_function = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key = EMBEDDING_KEY,\n",
    "                api_base = API_BASE_EMBEDDING ,\n",
    "                api_type = \"azure\",\n",
    "                api_version=\"2023-05-15\",\n",
    "                model_name=DEPLOYMENT_NAME_EMBEDDING\n",
    "            )\n",
    "\n",
    "# Define template for answers\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "{context}\n",
    "If you can't make a answer with context, just say that you don't know, don't try to make up an answer.\n",
    "Do not hallucinate.\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "question = \"\"\"Make as many relevant specific and/or generic questions that the above text can answer.\n",
    "If you can't make a question with context, just don't say anything, don't try to make up an questions just to fill the quota.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743fdeb-f194-43b1-b72d-563680fa97d3",
   "metadata": {},
   "source": [
    "## Load VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0387dd3b-0b02-4d0c-9df3-d841863c62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/load a local Croma database.\n",
    "persist_directory = 'embedding_OpenAI/chroma/'\n",
    "client = chromadb.PersistentClient(path = persist_directory)\n",
    "# Create or get a collection\n",
    "collection_full_text = client.get_or_create_collection(name = \"full_text\", embedding_function = embedding_function)\n",
    "collection_questions_text = client.get_or_create_collection(name = \"questions_text\", embedding_function = embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f5c69a-75a2-4b0c-b79f-e0b8325f41ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest index: 149\n"
     ]
    }
   ],
   "source": [
    "# Get last index\n",
    "# Get last id\n",
    "# Retrieve documents with metadata, which may contain IDs\n",
    "documents = collection_full_text.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "# Assuming your IDs are stored in the metadata and are numeric or sortable\n",
    "max_index = max([doc['vector_db_id'] for doc in documents['metadatas']], key=lambda x: int(x))\n",
    "\n",
    "print(f\"Largest index: {max_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9dbb793-e921-4e31-9c62-304045cd9771",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Adiciona na coleção para armazenar o texto completo\n",
    "add_text_collection_full_text = 1\n",
    "if add_text_collection_full_text == 1:\n",
    "    vector_db_id = max_index + 1\n",
    "    for e in tqdm.tqdm(chunks):\n",
    "        collection_full_text.add(\n",
    "            documents = e,\n",
    "            metadatas = {\"document_name\": document_name,\n",
    "                \"vector_db_id\": vector_db_id, \n",
    "                'first_page': -1, # This is a custom added text, so there isn't a first and last page.\n",
    "                'last_page': -1,\n",
    "                'added_by': added_by,\n",
    "            },\n",
    "            ids = [str(vector_db_id)]\n",
    "        )\n",
    "        # Questions\n",
    "        context = e\n",
    "        result = llm_chain.invoke({\"context\": context, \"question\": question})\n",
    "        collection_questions_text.add(\n",
    "            documents = result.content,\n",
    "            metadatas = {\"document_name\": document_name,\n",
    "                \"vector_db_id\": vector_db_id, \n",
    "                'first_page': -1, \n",
    "                'last_page': -1,\n",
    "                'added_by': added_by,\n",
    "            },\n",
    "            ids = [str(vector_db_id)]\n",
    "        )\n",
    "\n",
    "        vector_db_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f666760-2e5e-46ed-8530-08566e30f76d",
   "metadata": {},
   "source": [
    "## Verify if collections have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9d8898-7f98-4fff-a334-bead50667093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text largest index: 150\n",
      "Questions largest index: 150\n"
     ]
    }
   ],
   "source": [
    "# Create or get a collection\n",
    "collection_full_text_aux = client.get_or_create_collection(name = \"full_text\", embedding_function = embedding_function)\n",
    "collection_questions_aux = client.get_or_create_collection(name = \"questions_text\", embedding_function = embedding_function)\n",
    "\n",
    "# Get last index\n",
    "# Get last id\n",
    "# Retrieve documents with metadata, which may contain IDs\n",
    "documents_full_text = collection_full_text_aux.get(include=[\"documents\", \"metadatas\"])\n",
    "documents_questions_text = collection_questions_aux.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "# Assuming your IDs are stored in the metadata and are numeric or sortable\n",
    "max_index_full_text = max([doc['vector_db_id'] for doc in documents_full_text['metadatas']], key=lambda x: int(x))\n",
    "max_index_questions = max([doc['vector_db_id'] for doc in documents_questions_text['metadatas']], key=lambda x: int(x))\n",
    "\n",
    "\n",
    "print(f\"Full text largest index: {max_index_full_text}\")\n",
    "print(f\"Questions largest index: {max_index_questions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62cd84f-cf46-41bf-a686-279caacddf28",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7203d0-e715-4d0b-9e1a-cee6201b9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create/load a local Croma database.\n",
    "persist_directory = 'embedding_OpenAI/chroma/'\n",
    "client = chromadb.PersistentClient(path = persist_directory)\n",
    "\n",
    "chroma_instance_full_text = Chroma(\n",
    "    client = client,\n",
    "    collection_name = \"full_text\",\n",
    "    embedding_function = embedding_function_to_langchain,\n",
    ")\n",
    "chroma_instance_questions = Chroma(\n",
    "    client = client,\n",
    "    collection_name = \"questions_text\",\n",
    "    embedding_function = embedding_function_to_langchain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "863749da-726e-4c80-8783-3e73afe07c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['150'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['This is an example of how to add more information in your ChromaDb.\\nTo do so, just read this notebook.'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [{'added_by': 'Max Wienandts',\n",
       "   'document_name': 'Custon added',\n",
       "   'first_page': -1,\n",
       "   'last_page': -1,\n",
       "   'vector_db_id': 150}],\n",
       " 'included': [<IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the document based on its ID\n",
    "document_id = \"150\"  # Replace with the actual ID you are looking for\n",
    "result = chroma_instance_full_text.get(ids=[document_id])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4808d48-4e7b-4fba-bfcb-d227fb18c29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of how to add more information in your ChromaDb.\n",
      "To do so, just read this notebook.\n"
     ]
    }
   ],
   "source": [
    "text_to_find = 'This is an example of how to add more information in your ChromaDb.\\nTo do so, just read this notebook.'\n",
    "print(text_to_find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93be030f-30ce-4c6b-8a68-37bf4c27e738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='150', metadata={'added_by': 'Max Wienandts', 'document_name': 'Custon added', 'first_page': -1, 'last_page': -1, 'vector_db_id': 150}, page_content='This is an example of how to add more information in your ChromaDb.\\nTo do so, just read this notebook.'),\n",
       "  0.01594089670725535),\n",
       " (Document(id='149', metadata={'added_by': 'default', 'document_name': 'Custon added', 'first_page': -1, 'last_page': -1, 'vector_db_id': 149}, page_content='This is an example of how to add more information in your ChromaDb.\\nTo do so, just read this notebook.'),\n",
       "  0.01594089670725535)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = chroma_instance_full_text.similarity_search_with_score(\n",
    "    text_to_find,\n",
    "    k = 2,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aae3692f-e7f3-4ed2-9d70-3531a4803ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='150', metadata={'added_by': 'Max Wienandts', 'document_name': 'Custon added', 'first_page': -1, 'last_page': -1, 'vector_db_id': 150}, page_content='This is an example of how to add more information in your ChromaDb.\\nTo do so, just read this notebook.'),\n",
       "  0.01594089670725535)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = chroma_instance_full_text.similarity_search_with_score(\n",
    "    text_to_find,\n",
    "    k = 2,\n",
    "    filter={\"added_by\": {\"$in\": [added_by, 'deafult']}},\n",
    ")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
